\documentclass[6pt]{article}

\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables

\usepackage[pdftex]{graphicx}     
\usepackage{float}
\usepackage{titlesec}

\titleformat*{\section}{\small\bfseries}

\begin{document}

% \maketitle
\begin{center}
  \large 
  \textbf{Learning sentence representations from natural language inference data}
  
  \normalsize Konstantin Todorov, No. 12402559 \\
  Statistical Methods for Natural Language Semantics\\
  University of Amsterdam\\
\end{center}

\textbf{Github repository link - } https://github.com/ktodorov/uva-semantics-19\\

\vspace{1\baselineskip}

For all models we can observe that hypotheses where almost all of the sentence 
is similar to the premise the model predicts correctly as entailment but if
the differences in the hypothesis become more complex then the models fail
to predict correctly

\section{Mean encoder}

\begin{itemize}
  \item test macro accuracy: 61.4346\%
  
  \item test micro accuracy: 61.4413\%
  
  \item SentEval

  \begin{center}
    \begin{tabular}{| c |c | c | c | c|} 
        \hline
        & \textbf{devacc} & \textbf{acc} & \textbf{ndev} & \textbf{ntest} \\ 
        \hline
        \textbf{MR} & 77.87 & 76.63 & 10685 & 10685 \\ 
        \hline
        \textbf{CR} & 80.17 & 78.47 & 3775 & 3775 \\
        \hline
        \textbf{SUBJ} & 91.16 & 91.14 & 10021 & 10021 \\
        \hline
        \textbf{MPQA} & 87.51 & 87.57 & 10606 & 10606 \\
        \hline
        \textbf{TREC} & 73.59 & 82.6 & 5452 & 500 \\
        \hline
        \textbf{SST2} & 79.59 & 79.68 & 872 & 1821 \\
        \hline
        \textbf{MRPC} & 73.5 & 73.04 & 4076 & 1725 \\
        \hline
      \end{tabular}
    \end{center}
\end{itemize}

% {  
%    'deft-forum':{  
%       'pearson':(0.10614252529990185,
%       0.02433967284231164      ),
%       'spearman':SpearmanrResult(correlation=0.25221705591763377,
%       pvalue=5.848443081080422e-08),
%       'nsamples':450
%    },
%    'deft-news':{  
%       'pearson':(0.5613185278422829,
%       2.646342157885347e-26      ),
%       'spearman':SpearmanrResult(correlation=0.5687347715166986,
%       pvalue=4.172358748662268e-27),
%       'nsamples':300
%    },
%    'headlines':{  
%       'pearson':(0.4379333513210643,
%       1.7217396186027015e-36      ),
%       'spearman':SpearmanrResult(correlation=0.44064951845328976,
%       pvalue=5.662661537200817e-37),
%       'nsamples':750
%    },
%    'images':{  
%       'pearson':(0.4208953287757699,
%       1.4702273154142545e-33      ),
%       'spearman':SpearmanrResult(correlation=0.45905350353195695,
%       pvalue=2.3077385961213547e-40),
%       'nsamples':750
%    },
%    'OnWN':{  
%       'pearson':(0.4637601825924514,
%       2.9007064941307373e-41      ),
%       'spearman':SpearmanrResult(correlation=0.5207056013604293,
%       pvalue=2.3816261471973666e-53),
%       'nsamples':750
%    },
%    'tweet-news':{  
%       'pearson':(0.560871836590606,
%       2.3079172473519822e-63      ),
%       'spearman':SpearmanrResult(correlation=0.5732894470474054,
%       pvalue=9.585354391511192e-67),
%       'nsamples':750
%    },
%    'all':{  
%       'pearson':{  
%          'mean':0.4251536254036794,
%          'wmean':0.43433472511934923
%       },
%       'spearman':{  
%          'mean':0.4691083163045689,
%          'wmean':0.47450444251006824
%       }
%    }
% }
\section{Uni-LSTM encoder}

\begin{itemize}
  \item test macro accuracy: 33.7865\%
  
  \item test micro accuracy: 33.7438\%
\end{itemize}

\section{Bi-LSTM encoder}

\begin{itemize}
  \item test macro accuracy: 34.4460\%
  
  \item test micro accuracy: 34.4258\%
\end{itemize}

\section{Bi-LSTM with max-pooling encoder}

\begin{itemize}
  \item test macro accuracy: 37.6724\%
  
  \item test micro accuracy: 37.6832\%
\end{itemize}

\end{document}